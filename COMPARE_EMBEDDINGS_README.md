# Embedding Comparison Script

This script compares embeddings generated by Ollama with those from HuggingFace SentenceTransformers to validate model conversion quality.

## Installation

```bash
pip install -r requirements_compare.txt
```

## Usage

### Basic Usage (JSONL file)

```bash
python compare_embeddings.py sample_data.jsonl --json-path text
```

### With Custom Models

```bash
python compare_embeddings.py sample_data.jsonl \
    --json-path text \
    --ollama-model granite-r2 \
    --hf-model ibm-granite/granite-embedding-english-r2
```

### With Custom Ollama Server

```bash
python compare_embeddings.py sample_data.jsonl \
    --json-path text \
    --ollama-host http://127.0.0.1:13000
```

### Limit Samples and Save Results

```bash
python compare_embeddings.py data.jsonl \
    --json-path text \
    --limit 100 \
    --output results.json
```

### Nested JSON Path

For JSON with nested structure:

```json
{
  "data": {
    "content": "This is the text to embed"
  }
}
```

Use:
```bash
python compare_embeddings.py data.json --json-path data.content
```

## Input File Formats

### JSONL Format
```jsonl
{"text": "First sentence"}
{"text": "Second sentence"}
```

### JSON Array Format
```json
[
  {"text": "First sentence"},
  {"text": "Second sentence"}
]
```

### JSON Single Object
```json
{"text": "Single sentence"}
```

## Output

The script outputs:
- Per-sample comparison with cosine similarity
- Summary statistics (mean, median, std, min, max)
- Distribution of similarity scores
- Optional detailed JSON output file

### Example Output

```
[1/5] Processing: The quick brown fox jumps over the lazy dog
  Ollama dim: 768, norm: 1.0000
  HF dim: 768, norm: 1.0000
  Cosine similarity: 0.999823

================================================================================
SUMMARY
================================================================================
Total samples processed: 5
Cosine Similarity Statistics:
  Mean:   0.998456
  Median: 0.998891
  Std:    0.001234
  Min:    0.995432
  Max:    0.999823

Distribution:
  < 0.900:    0 (0.0%)
  [0.900, 0.950):   0 (0.0%)
  [0.950, 0.990):   0 (0.0%)
  [0.990, 0.999):   1 (20.0%)
  [0.999, 1.000):   4 (80.0%)
```

## Notes

- High cosine similarity (>0.99) indicates the Ollama conversion matches the reference implementation well
- Both embeddings are normalized before comparison
- The script handles errors gracefully and continues processing remaining samples
